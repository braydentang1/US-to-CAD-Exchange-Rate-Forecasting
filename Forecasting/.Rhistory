View(results)
View(timeSlices)
timeSlices = createTimeSlices(y = data.ts, initialWindow = 560, horizon = 3, fixedWindow = FALSE)
View(timeSlices)
View(timeSlices)
View(timeSlices)
timeSlices = createTimeSlices(y = data.ts, initialWindow = 565, horizon = 3, fixedWindow = FALSE)
View(timeSlices)
source('~/GitHub/US-to-CAD-Exchange-Rate-Forecasting/Forecasting/Initial Exploration.R', echo=TRUE)
View(results)
timeSlices = createTimeSlices(y = data.ts, initialWindow = 565, horizon = 3, fixedWindow = FALSE)
library(tidyverse)
library(forecast)
library(caret)
#......................Import Data..........................................#
data = read_csv("C:/Users/Brayden/Documents/GitHub/US-to-CAD-Exchange-Rate-Forecasting/Data/EXCAUS.csv")
data.ts = ts(data$EXCAUS, frequency = 12, start = c(1971,1), end = c(2019,4))
#......................Fit the ensemble model...............................#
innerTrain = function(outerTrain, data, iterations){
set.seed(200350623)
randomGrid = tibble(ETS.Weight = sample.int(10000, size = iterations, replace = TRUE), Theta.Weight = sample.int(10000, size = iterations, replace = TRUE),
RWD.Weight = sample.int(10000, size = iterations, replace = TRUE), TBATS.Weight = sample.int(10000, size = iterations, replace = TRUE),
STL.Weight = sample.int(10000, size = iterations, replace = TRUE)) %>%
mutate(sumofWeights = rowSums(.))
allInnerSets = createTimeSlices(y = outerTrain, initialWindow = 550, horizon = 3, fixedWindow = FALSE)
allInnerTrain = allInnerSets$train
allValidation = allInnerSets$test
scores = vector("list", length(allInnerTrain))
for(k in 1:length(allInnerTrain)){
train.time = time(data)[allInnerTrain[[k]]]
train = window(data, start = train.time[1], end = train.time[length(train.time)])
validation.time = time(data)[allValidation[[k]]]
validation = window(data, start = validation.time[1], end = validation.time[length(validation.time)])
allPredictions = grabPredictions(train = train, newdata = validation) %>%
reduce(ts.intersect) %>%
as_tibble(.) %>%
set_names(c("ETS", "Theta", "RWD", "TBATS", "STL"))
scores[[k]] = randomGridSearch(grid = randomGrid, predictions = allPredictions, validation = validation)
}
finalGrid = scores %>% reduce(cbind) %>% rowMeans(.) %>% bind_cols(randomGrid, Score = .)
finalParameters = finalGrid[which.min(finalGrid$Score), ]
finalParameters
}
outerFold = function(data, trainFoldsIndex, testFoldsIndex, parameters){
outerTrain.time = time(data)[trainFoldsIndex]
outerTrain = window(data, start = outerTrain.time[1], end = outerTrain.time[length(outerTrain.time)])
test.time = time(data)[testFoldsIndex]
test = window(data, start = test.time[1], end = test.time[length(test.time)])
finalPredictions = grabPredictions(train = outerTrain, newdata = test) %>%
reduce(ts.intersect) %>%
as_tibble(.) %>%
set_names(c("ETS", "Theta", "RWD", "TBATS", "STL"))
score = randomGridSearch(grid = parameters, predictions = finalPredictions, validation = test)
score
}
grabPredictions = function(train, newdata){
model.Average = vector("list", 5)
ets.model = ets(train, ic = "aicc")
forecast.ets = forecast(ets.model, h = length(newdata))
model.Average[[1]] = forecast.ets$mean
forecast.theta = thetaf(y = train, h = length(newdata))
model.Average[[2]] = forecast.theta$mean
forecast.rwd = rwf(y = train, h = length(newdata), drift = TRUE)
model.Average[[3]] = forecast.rwd$mean
model.tbats = tbats(y = train, num.cores = 4)
forecast.tbats = forecast(model.tbats, h=length(newdata))
model.Average[[4]] = forecast.tbats$mean
forecast.STL = stlf(y = train, h = length(newdata), robust = TRUE)
model.Average[[5]] = forecast.STL$mean
model.Average
}
randomGridSearch = function(grid, predictions, validation){
score = vector("numeric", nrow(grid))
for (k in 1:nrow(grid)){
predictions.tmp = predictions %>% transmute(Weighted.Average = ETS * as.numeric(grid[k,1]/grid[k,6]) + Theta * as.numeric(grid[k,2]/grid[k,6]) +
RWD * as.numeric(grid[k,3]/grid[k,6]) + TBATS * as.numeric(grid[k,4]/grid[k,6]) + STL * as.numeric(grid[k,5]/grid[k,6]))
score[k] = accuracy(f = predictions.tmp$Weighted.Average, x = validation)[2]
}
score
}
timeSlices = createTimeSlices(y = data.ts, initialWindow = 565, horizon = 3, fixedWindow = FALSE)
outerTrain = timeSlices$train
data = data.ts
iterations = 3
set.seed(200350623)
randomGrid = tibble(ETS.Weight = sample.int(10000, size = iterations, replace = TRUE), Theta.Weight = sample.int(10000, size = iterations, replace = TRUE),
RWD.Weight = sample.int(10000, size = iterations, replace = TRUE), TBATS.Weight = sample.int(10000, size = iterations, replace = TRUE),
STL.Weight = sample.int(10000, size = iterations, replace = TRUE)) %>%
mutate(sumofWeights = rowSums(.))
allInnerSets = createTimeSlices(y = outerTrain, initialWindow = 550, horizon = 3, fixedWindow = FALSE)
allInnerTrain = allInnerSets$train
allValidation = allInnerSets$test
scores = vector("list", length(allInnerTrain))
allInnerSets = createTimeSlices(y = outerTrain, initialWindow = 550, horizon = 3, fixedWindow = FALSE)
View(outerTrain)
View(outerTrain)
View(outerTrain)
View(outerTrain)
View(timeSlices)
source('~/GitHub/US-to-CAD-Exchange-Rate-Forecasting/Forecasting/Ensemble Method - Weighted Average.R', echo=TRUE)
bestParameters = lapply(timeSlices$train, FUN = innerTrain, data = data.ts, iterations = 2)
View(timeSlices)
outerTrain = timeSlices$train
data = data.ts
iterations = 2
set.seed(200350623)
randomGrid = tibble(ETS.Weight = sample.int(10000, size = iterations, replace = TRUE), Theta.Weight = sample.int(10000, size = iterations, replace = TRUE),
RWD.Weight = sample.int(10000, size = iterations, replace = TRUE), TBATS.Weight = sample.int(10000, size = iterations, replace = TRUE),
STL.Weight = sample.int(10000, size = iterations, replace = TRUE)) %>%
mutate(sumofWeights = rowSums(.))
allInnerSets = createTimeSlices(y = outerTrain, initialWindow = 550, horizon = 3, fixedWindow = FALSE)
View(outerTrain)
View(outerTrain)
allInnerSets = createTimeSlices(y = outerTrain[[1]], initialWindow = 550, horizon = 3, fixedWindow = FALSE)
View(allInnerSets)
allInnerSets = createTimeSlices(y = outerTrain[[1]], initialWindow = 560, horizon = 3, fixedWindow = FALSE)
View(allInnerSets)
allInnerSets = createTimeSlices(y = outerTrain[[1]], initialWindow = 570, horizon = 3, fixedWindow = FALSE)
View(outerTrain)
outerTrain[["Training565"]]
allInnerSets = createTimeSlices(y = outerTrain[[1]], initialWindow = 560, horizon = 3, fixedWindow = FALSE)
View(allInnerSets)
View(allInnerSets)
allInnerSets = createTimeSlices(y = outerTrain[[1]], initialWindow = 565, horizon = 3, fixedWindow = FALSE)
allInnerSets = createTimeSlices(y = outerTrain[[1]], initialWindow = 563, horizon = 3, fixedWindow = FALSE)
allInnerSets = createTimeSlices(y = outerTrain[[1]], initialWindow = 562, horizon = 3, fixedWindow = FALSE)
View(allInnerSets)
View(allInnerSets)
View(allInnerSets)
View(outerTrain)
allInnerSets = createTimeSlices(y = outerTrain[[1]], initialWindow = 557, horizon = 3, fixedWindow = FALSE)
View(allInnerSets)
View(allInnerSets)
View(allInnerSets)
allInnerSets = createTimeSlices(y = outerTrain[[1]], initialWindow = 558, horizon = 3, fixedWindow = FALSE)
View(allInnerSets)
View(allInnerSets)
View(allInnerSets)
View(timeSlices)
library(tidyverse)
library(forecast)
library(caret)
#......................Import Data..........................................#
data = read_csv("C:/Users/Brayden/Documents/GitHub/US-to-CAD-Exchange-Rate-Forecasting/Data/EXCAUS.csv")
data.ts = ts(data$EXCAUS, frequency = 12, start = c(1971,1), end = c(2019,4))
#......................Fit the ensemble model...............................#
innerTrain = function(trainFoldsIndex, data, iterations){
set.seed(200350623)
randomGrid = tibble(ETS.Weight = sample.int(10000, size = iterations, replace = TRUE), Theta.Weight = sample.int(10000, size = iterations, replace = TRUE),
RWD.Weight = sample.int(10000, size = iterations, replace = TRUE), TBATS.Weight = sample.int(10000, size = iterations, replace = TRUE),
STL.Weight = sample.int(10000, size = iterations, replace = TRUE)) %>%
mutate(sumofWeights = rowSums(.))
outerTrain.time = time(data)[trainFoldsIndex]
outerTrain = window(data, start = outerTrain.time[1], end = outerTrain.time[length(outerTrain.time)])
allInnerSets = createTimeSlices(y = outerTrain, initialWindow = 558, horizon = 3, fixedWindow = FALSE)
allInnerTrain = allInnerSets$train
allValidation = allInnerSets$test
scores = vector("list", length(allInnerTrain))
for(k in 1:length(allInnerTrain)){
train.time = time(data)[allInnerTrain[[k]]]
train = window(data, start = train.time[1], end = train.time[length(train.time)])
validation.time = time(data)[allValidation[[k]]]
validation = window(data, start = validation.time[1], end = validation.time[length(validation.time)])
allPredictions = grabPredictions(train = train, newdata = validation) %>%
reduce(ts.intersect) %>%
as_tibble(.) %>%
set_names(c("ETS", "Theta", "RWD", "TBATS", "STL"))
scores[[k]] = randomGridSearch(grid = randomGrid, predictions = allPredictions, validation = validation)
}
finalGrid = scores %>% reduce(cbind) %>% rowMeans(.) %>% bind_cols(randomGrid, Score = .)
finalParameters = finalGrid[which.min(finalGrid$Score), ]
finalParameters
}
outerFold = function(data, trainFoldsIndex, testFoldsIndex, parameters){
outerTrain.time = time(data)[trainFoldsIndex]
outerTrain = window(data, start = outerTrain.time[1], end = outerTrain.time[length(outerTrain.time)])
test.time = time(data)[testFoldsIndex]
test = window(data, start = test.time[1], end = test.time[length(test.time)])
finalPredictions = grabPredictions(train = outerTrain, newdata = test) %>%
reduce(ts.intersect) %>%
as_tibble(.) %>%
set_names(c("ETS", "Theta", "RWD", "TBATS", "STL"))
score = randomGridSearch(grid = parameters, predictions = finalPredictions, validation = test)
score
}
grabPredictions = function(train, newdata){
model.Average = vector("list", 5)
ets.model = ets(train, ic = "aicc")
forecast.ets = forecast(ets.model, h = length(newdata))
model.Average[[1]] = forecast.ets$mean
forecast.theta = thetaf(y = train, h = length(newdata))
model.Average[[2]] = forecast.theta$mean
forecast.rwd = rwf(y = train, h = length(newdata), drift = TRUE)
model.Average[[3]] = forecast.rwd$mean
model.tbats = tbats(y = train, num.cores = 4)
forecast.tbats = forecast(model.tbats, h=length(newdata))
model.Average[[4]] = forecast.tbats$mean
forecast.STL = stlf(y = train, h = length(newdata), robust = TRUE)
model.Average[[5]] = forecast.STL$mean
model.Average
}
randomGridSearch = function(grid, predictions, validation){
score = vector("numeric", nrow(grid))
for (k in 1:nrow(grid)){
predictions.tmp = predictions %>% transmute(Weighted.Average = ETS * as.numeric(grid[k,1]/grid[k,6]) + Theta * as.numeric(grid[k,2]/grid[k,6]) +
RWD * as.numeric(grid[k,3]/grid[k,6]) + TBATS * as.numeric(grid[k,4]/grid[k,6]) + STL * as.numeric(grid[k,5]/grid[k,6]))
score[k] = accuracy(f = predictions.tmp$Weighted.Average, x = validation)[2]
}
score
}
timeSlices = createTimeSlices(y = data.ts, initialWindow = 565, horizon = 3, fixedWindow = FALSE)
trainFoldsIndex = timeSlices$train
data = data.ts
iterations = 3
set.seed(200350623)
randomGrid = tibble(ETS.Weight = sample.int(10000, size = iterations, replace = TRUE), Theta.Weight = sample.int(10000, size = iterations, replace = TRUE),
RWD.Weight = sample.int(10000, size = iterations, replace = TRUE), TBATS.Weight = sample.int(10000, size = iterations, replace = TRUE),
STL.Weight = sample.int(10000, size = iterations, replace = TRUE)) %>%
mutate(sumofWeights = rowSums(.))
outerTrain.time = time(data)[trainFoldsIndex]
outerTrain = window(data, start = outerTrain.time[1], end = outerTrain.time[length(outerTrain.time)])
allInnerSets = createTimeSlices(y = outerTrain, initialWindow = 558, horizon = 3, fixedWindow = FALSE)
allInnerTrain = allInnerSets$train
allValidation = allInnerSets$test
scores = vector("list", length(allInnerTrain))
View(trainFoldsIndex)
View(trainFoldsIndex)
trainsFoldIndex = timeSlices$train[[1]]
View(trainFoldsIndex)
trainsFoldIndex = timeSlices$train[[1]]
trainFoldIndex = timeSlices$train[[1]]
rm(trainsFoldIndex)
set.seed(200350623)
randomGrid = tibble(ETS.Weight = sample.int(10000, size = iterations, replace = TRUE), Theta.Weight = sample.int(10000, size = iterations, replace = TRUE),
RWD.Weight = sample.int(10000, size = iterations, replace = TRUE), TBATS.Weight = sample.int(10000, size = iterations, replace = TRUE),
STL.Weight = sample.int(10000, size = iterations, replace = TRUE)) %>%
mutate(sumofWeights = rowSums(.))
outerTrain.time = time(data)[trainFoldsIndex]
outerTrain = window(data, start = outerTrain.time[1], end = outerTrain.time[length(outerTrain.time)])
allInnerSets = createTimeSlices(y = outerTrain, initialWindow = 558, horizon = 3, fixedWindow = FALSE)
allInnerTrain = allInnerSets$train
allValidation = allInnerSets$test
scores = vector("list", length(allInnerTrain))
set.seed(200350623)
randomGrid = tibble(ETS.Weight = sample.int(10000, size = iterations, replace = TRUE), Theta.Weight = sample.int(10000, size = iterations, replace = TRUE),
RWD.Weight = sample.int(10000, size = iterations, replace = TRUE), TBATS.Weight = sample.int(10000, size = iterations, replace = TRUE),
STL.Weight = sample.int(10000, size = iterations, replace = TRUE)) %>%
mutate(sumofWeights = rowSums(.))
outerTrain.time = time(data)[trainFoldIndex]
outerTrain = window(data, start = outerTrain.time[1], end = outerTrain.time[length(outerTrain.time)])
allInnerSets = createTimeSlices(y = outerTrain, initialWindow = 558, horizon = 3, fixedWindow = FALSE)
allInnerTrain = allInnerSets$train
allValidation = allInnerSets$test
scores = vector("list", length(allInnerTrain))
outerTrain
k = 1
train.time = time(data)[allInnerTrain[[k]]]
train = window(data, start = train.time[1], end = train.time[length(train.time)])
validation.time = time(data)[allValidation[[k]]]
validation = window(data, start = validation.time[1], end = validation.time[length(validation.time)])
train
test
validation
k = 2
train.time = time(data)[allInnerTrain[[k]]]
train = window(data, start = train.time[1], end = train.time[length(train.time)])
validation.time = time(data)[allValidation[[k]]]
validation = window(data, start = validation.time[1], end = validation.time[length(validation.time)])
train
test
validation
View(timeSlices)
testFoldsIndex = timeSlices$test[[1]]
test = window(data, start = test.time[1], end = test.time[length(test.time)])
test.time = time(data)[testFoldsIndex]
test = window(data, start = test.time[1], end = test.time[length(test.time)])
test
library(tidyverse)
library(forecast)
library(caret)
#......................Import Data..........................................#
data = read_csv("C:/Users/Brayden/Documents/GitHub/US-to-CAD-Exchange-Rate-Forecasting/Data/EXCAUS.csv")
data.ts = ts(data$EXCAUS, frequency = 12, start = c(1971,1), end = c(2019,4))
#......................Fit the ensemble model...............................#
innerTrain = function(trainFoldIndex, data, iterations){
set.seed(200350623)
randomGrid = tibble(ETS.Weight = sample.int(10000, size = iterations, replace = TRUE), Theta.Weight = sample.int(10000, size = iterations, replace = TRUE),
RWD.Weight = sample.int(10000, size = iterations, replace = TRUE), TBATS.Weight = sample.int(10000, size = iterations, replace = TRUE),
STL.Weight = sample.int(10000, size = iterations, replace = TRUE)) %>%
mutate(sumofWeights = rowSums(.))
outerTrain.time = time(data)[trainFoldIndex]
outerTrain = window(data, start = outerTrain.time[1], end = outerTrain.time[length(outerTrain.time)])
allInnerSets = createTimeSlices(y = outerTrain, initialWindow = 558, horizon = 3, fixedWindow = FALSE)
allInnerTrain = allInnerSets$train
allValidation = allInnerSets$test
scores = vector("list", length(allInnerTrain))
for(k in 1:length(allInnerTrain)){
train.time = time(data)[allInnerTrain[[k]]]
train = window(data, start = train.time[1], end = train.time[length(train.time)])
validation.time = time(data)[allValidation[[k]]]
validation = window(data, start = validation.time[1], end = validation.time[length(validation.time)])
allPredictions = grabPredictions(train = train, newdata = validation) %>%
reduce(ts.intersect) %>%
as_tibble(.) %>%
set_names(c("ETS", "Theta", "RWD", "TBATS", "STL"))
scores[[k]] = randomGridSearch(grid = randomGrid, predictions = allPredictions, validation = validation)
}
finalGrid = scores %>% reduce(cbind) %>% rowMeans(.) %>% bind_cols(randomGrid, Score = .)
finalParameters = finalGrid[which.min(finalGrid$Score), ]
finalParameters
}
outerFold = function(data, trainFoldsIndex, testFoldsIndex, parameters){
outerTrain.time = time(data)[trainFoldsIndex]
outerTrain = window(data, start = outerTrain.time[1], end = outerTrain.time[length(outerTrain.time)])
test.time = time(data)[testFoldsIndex]
test = window(data, start = test.time[1], end = test.time[length(test.time)])
finalPredictions = grabPredictions(train = outerTrain, newdata = test) %>%
reduce(ts.intersect) %>%
as_tibble(.) %>%
set_names(c("ETS", "Theta", "RWD", "TBATS", "STL"))
score = randomGridSearch(grid = parameters, predictions = finalPredictions, validation = test)
score
}
grabPredictions = function(train, newdata){
model.Average = vector("list", 5)
ets.model = ets(train, ic = "aicc")
forecast.ets = forecast(ets.model, h = length(newdata))
model.Average[[1]] = forecast.ets$mean
forecast.theta = thetaf(y = train, h = length(newdata))
model.Average[[2]] = forecast.theta$mean
forecast.rwd = rwf(y = train, h = length(newdata), drift = TRUE)
model.Average[[3]] = forecast.rwd$mean
model.tbats = tbats(y = train, num.cores = 4)
forecast.tbats = forecast(model.tbats, h=length(newdata))
model.Average[[4]] = forecast.tbats$mean
forecast.STL = stlf(y = train, h = length(newdata), robust = TRUE)
model.Average[[5]] = forecast.STL$mean
model.Average
}
randomGridSearch = function(grid, predictions, validation){
score = vector("numeric", nrow(grid))
for (k in 1:nrow(grid)){
predictions.tmp = predictions %>% transmute(Weighted.Average = ETS * as.numeric(grid[k,1]/grid[k,6]) + Theta * as.numeric(grid[k,2]/grid[k,6]) +
RWD * as.numeric(grid[k,3]/grid[k,6]) + TBATS * as.numeric(grid[k,4]/grid[k,6]) + STL * as.numeric(grid[k,5]/grid[k,6]))
score[k] = accuracy(f = predictions.tmp$Weighted.Average, x = validation)[2]
}
score
}
timeSlices = createTimeSlices(y = data.ts, initialWindow = 565, horizon = 3, fixedWindow = FALSE)
train = timeSlices$train[[1]]
rm(train)
trainFoldIndex = timeSlices$train[[1]]
data = data.ts
iterations = 3
set.seed(200350623)
randomGrid = tibble(ETS.Weight = sample.int(10000, size = iterations, replace = TRUE), Theta.Weight = sample.int(10000, size = iterations, replace = TRUE),
RWD.Weight = sample.int(10000, size = iterations, replace = TRUE), TBATS.Weight = sample.int(10000, size = iterations, replace = TRUE),
STL.Weight = sample.int(10000, size = iterations, replace = TRUE)) %>%
mutate(sumofWeights = rowSums(.))
outerTrain.time = time(data)[trainFoldIndex]
outerTrain = window(data, start = outerTrain.time[1], end = outerTrain.time[length(outerTrain.time)])
allInnerSets = createTimeSlices(y = outerTrain, initialWindow = 558, horizon = 3, fixedWindow = FALSE)
allInnerTrain = allInnerSets$train
allValidation = allInnerSets$test
scores = vector("list", length(allInnerTrain))
outerTrain
testFoldsIndex = timeSlices$test[[1]]
test.time = time(data)[testFoldsIndex]
test = window(data, start = test.time[1], end = test.time[length(test.time)])
test
k = 1
train.time = time(data)[allInnerTrain[[k]]]
train = window(data, start = train.time[1], end = train.time[length(train.time)])
train
validation.time = time(data)[allValidation[[k]]]
validation = window(data, start = validation.time[1], end = validation.time[length(validation.time)])
validation
k = 2
train.time = time(data)[allInnerTrain[[k]]]
train = window(data, start = train.time[1], end = train.time[length(train.time)])
train
validation.time = time(data)[allValidation[[k]]]
validation = window(data, start = validation.time[1], end = validation.time[length(validation.time)])
validation
k = 3
outerTrain
test
source('~/GitHub/US-to-CAD-Exchange-Rate-Forecasting/Forecasting/Ensemble Method - Weighted Average.R', echo=TRUE)
data.ts
source('~/GitHub/US-to-CAD-Exchange-Rate-Forecasting/Forecasting/Ensemble Method - Weighted Average.R', echo=TRUE)
cluster = makeCluster(detectCores())
library(parallel)
cluster = makeCluster(detectCores())
?clusterEvalQ
cluster = makeCluster(detectCores())
setDefaultCluster(cluster)
clusterEvalQ(NULL, library(caret), library(forecast), library(tidyverse))
clusterEvalQ(NULL, c(library(caret), library(forecast), library(tidyverse)))
clusterEvalQ(NULL, "library(caret), library(forecast), library(tidyverse)")
clusterEvalQ(NULL, library(caret), library(forecast), library(tidyverse))
cluster = makeCluster(detectCores())
setDefaultCluster(cluster)
clusterEvalQ(cluster, library(caret))
clusterEvalQ(cluster, library(tidyverse))
clusterEvalQ(cluster, library(forecast))
stopCluster(cluster)
source('~/GitHub/US-to-CAD-Exchange-Rate-Forecasting/Forecasting/Ensemble Method - Weighted Average.R', echo=TRUE)
stopCluster(cluster)
source('~/GitHub/US-to-CAD-Exchange-Rate-Forecasting/Forecasting/Ensemble Method - Weighted Average.R', echo=TRUE)
View(finalResults)
finalResults[["Training565"]]
source('~/GitHub/US-to-CAD-Exchange-Rate-Forecasting/Forecasting/Ensemble Method - Weighted Average.R', echo=TRUE)
source('~/GitHub/US-to-CAD-Exchange-Rate-Forecasting/Forecasting/Single Models and Simple Ensemble.R', echo=TRUE)
source('~/GitHub/US-to-CAD-Exchange-Rate-Forecasting/Forecasting/Single Models and Simple Ensemble.R', echo=TRUE)
View(results)
View(timeSlices)
abc = unlist(results)
which.min(abc)
abc = abc[!= 0]
abc = abc[abc != 0]
which.min(abc)
abc[which.min(abc)]
timeSlices = createTimeSlices(y = data.ts, initialWindow = 560, horizon = 3, fixedWindow = FALSE)
library(tidyverse)
library(forecast)
library(caret)
library(parallel)
#0.02144643 RMSE
#Worse than best single method RWD.
#......................Import Data..........................................#
data = read_csv("C:/Users/Brayden/Documents/GitHub/US-to-CAD-Exchange-Rate-Forecasting/Data/EXCAUS.csv")
data.ts = ts(data$EXCAUS, frequency = 12, start = c(1971,1), end = c(2019,4))
#......................Fit the ensemble model...............................#
innerTrain = function(trainFoldIndex, data, iterations){
set.seed(200350623)
randomGrid = tibble(ETS.Weight = sample.int(10000, size = iterations, replace = TRUE), Theta.Weight = sample.int(10000, size = iterations, replace = TRUE),
RWD.Weight = sample.int(10000, size = iterations, replace = TRUE), TBATS.Weight = sample.int(10000, size = iterations, replace = TRUE),
STL.Weight = sample.int(10000, size = iterations, replace = TRUE)) %>%
mutate(sumofWeights = rowSums(.))
outerTrain.time = time(data)[trainFoldIndex]
outerTrain = window(data, start = outerTrain.time[1], end = outerTrain.time[length(outerTrain.time)])
allInnerSets = createTimeSlices(y = outerTrain, initialWindow = 550, horizon = 3, fixedWindow = FALSE)
allInnerTrain = allInnerSets$train
allValidation = allInnerSets$test
scores = vector("list", length(allInnerTrain))
for(k in 1:length(allInnerTrain)){
train.time = time(data)[allInnerTrain[[k]]]
train = window(data, start = train.time[1], end = train.time[length(train.time)])
validation.time = time(data)[allValidation[[k]]]
validation = window(data, start = validation.time[1], end = validation.time[length(validation.time)])
allPredictions = grabPredictions(train = train, newdata = validation) %>%
reduce(ts.intersect) %>%
as_tibble(.) %>%
set_names(c("ETS", "Theta", "RWD", "TBATS", "STL"))
scores[[k]] = randomGridSearch(grid = randomGrid, predictions = allPredictions, validation = validation)
}
finalGrid = scores %>% reduce(cbind) %>% rowMeans(.) %>% bind_cols(randomGrid, Score = .)
finalParameters = finalGrid[which.min(finalGrid$Score), ]
finalParameters
}
outerFold = function(data, trainFoldsIndex, testFoldsIndex, parameters){
outerTrain.time = time(data)[trainFoldsIndex]
outerTrain = window(data, start = outerTrain.time[1], end = outerTrain.time[length(outerTrain.time)])
test.time = time(data)[testFoldsIndex]
test = window(data, start = test.time[1], end = test.time[length(test.time)])
finalPredictions = grabPredictions(train = outerTrain, newdata = test) %>%
reduce(ts.intersect) %>%
as_tibble(.) %>%
set_names(c("ETS", "Theta", "RWD", "TBATS", "STL"))
score = randomGridSearch(grid = parameters, predictions = finalPredictions, validation = test)
score
}
grabPredictions = function(train, newdata){
model.Average = vector("list", 5)
ets.model = ets(train, ic = "aicc")
forecast.ets = forecast(ets.model, h = length(newdata))
model.Average[[1]] = forecast.ets$mean
forecast.theta = thetaf(y = train, h = length(newdata))
model.Average[[2]] = forecast.theta$mean
forecast.rwd = rwf(y = train, h = length(newdata), drift = TRUE)
model.Average[[3]] = forecast.rwd$mean
model.tbats = tbats(y = train, num.cores = 4)
forecast.tbats = forecast(model.tbats, h=length(newdata))
model.Average[[4]] = forecast.tbats$mean
forecast.STL = stlf(y = train, h = length(newdata), robust = TRUE)
model.Average[[5]] = forecast.STL$mean
model.Average
}
randomGridSearch = function(grid, predictions, validation){
score = vector("numeric", nrow(grid))
for (k in 1:nrow(grid)){
predictions.tmp = predictions %>% transmute(Weighted.Average = ETS * as.numeric(grid[k,1]/grid[k,6]) + Theta * as.numeric(grid[k,2]/grid[k,6]) +
RWD * as.numeric(grid[k,3]/grid[k,6]) + TBATS * as.numeric(grid[k,4]/grid[k,6]) + STL * as.numeric(grid[k,5]/grid[k,6]))
score[k] = accuracy(f = predictions.tmp$Weighted.Average, x = validation)[2]
}
score
}
timeSlices = createTimeSlices(y = data.ts, initialWindow = 560, horizon = 3, fixedWindow = FALSE)
View(timeSlices)
timeSlices.v2 = createTimeSlices(y = data.ts, initialWindow = 560, horizon = 3, fixedWindow = FALSE)
View(timeSlices.v2)
View(timeSlices)
View(timeSlices)
View(timeSlices.v2)
source('~/GitHub/US-to-CAD-Exchange-Rate-Forecasting/Forecasting/Ensemble Method - Weighted Average.R', echo=TRUE)
warnings()
View(finalResults)
abc = expand.grid(gamma = 10^(-1:2), cost = 10^(-0.5:1))
View(abc)
10^(-1:2)
10^(-0.5:1)
-0.5:1
